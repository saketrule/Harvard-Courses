{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIT 15.439\n",
    "### Problem Set 2\n",
    "---------------------\n",
    "\n",
    "#### MIT Collaboration Note\n",
    "\n",
    "This homework was completed in accordance with the syllabus and MIT policies on Group Work (Type 3 collaboration). Team members (cross-registered from Harvard): \n",
    "1. Saket Joshi [saket_joshi@g.harvard.edu](saket\\_joshi@g.harvard.edu)\n",
    "2. Siddhant Mukherjee []()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scipy) (1.24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sid/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sid/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sid/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sid/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install scipy\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class norm_ret:\n",
    "    def __init__(self,ret,std):\n",
    "        self.ret = ret\n",
    "        self.std = std\n",
    "    def prob_loss_normal(self):\n",
    "        return stats.norm.cdf(-self.ret/self.std)\n",
    "    def get_win_rate(self):\n",
    "        return round(1-self.prob_loss_normal(),4)\n",
    "    def get_up_down(self):\n",
    "        down = self.ret+\\\n",
    "            self.std*stats.norm.expect\\\n",
    "                (lb=-10,ub=-self.ret/self.std)\n",
    "        up = self.ret+self.std*stats.norm.expect\\\n",
    "                (lb=-self.ret/self.std,ub=10)\n",
    "        return round(-up/down,4)\n",
    "    def get_sharpe(self):\n",
    "        return round(self.ret/self.std,4)\n",
    "    def adjust_time(self,time_factor):\n",
    "        return norm_ret(self.ret*time_factor,\\\n",
    "                        self.std*(time_factor)**0.5)\n",
    "    \n",
    "def prob_drawdown(annual_ret_pair,time,max_iters=10000,drawdown_days=90):\n",
    "    daily_ret = annual_ret_pair.adjust_time(1/252)\n",
    "    ret  = daily_ret.ret\n",
    "    std = daily_ret.std\n",
    "    returns = np.random.normal(ret,std,(max_iters,252*time))\n",
    "    cum_returns = np.cumsum(returns,axis=1)\n",
    "    high_water_values = np.maximum.accumulate(cum_returns,axis=1)\n",
    "    is_high_water_mark = high_water_values==cum_returns\n",
    "    high_water_marks = [np.argwhere(is_high_water_mark[i,:])[:,0]\\\n",
    "                                 for i in range(max_iters)]\n",
    "    large_drawdown = np.array([np.max\\\n",
    "                               (item[1:]-item[:-1],initial=252*time-1-item[-1])\\\n",
    "                                  for item in high_water_marks])\n",
    "    enough_drawdown = np.sum(large_drawdown>=drawdown_days,axis=0)\n",
    "    return enough_drawdown/max_iters\n",
    "def display_table(rows, columns, data):\n",
    "     print(\"\\t\",end=\"\")\n",
    "     for column in columns:\n",
    "          print(f\"\\t{column}\",end=\"\")\n",
    "     print()\n",
    "     for row_index, row in enumerate(rows):\n",
    "          print(f\"\\t{row}\",end=\"\")\n",
    "          for column_index, column in enumerate(columns):\n",
    "               print(f\"\\t{data[row_index][column_index]}\",end=\"\")\n",
    "          print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Problem A\n",
    "\n",
    "**A.i.** Probability of losing money in a year = 2.28%\n",
    "\n",
    "**A.ii.** Probability of losing money in a year = 15.87%\n",
    "\n",
    "**A.iii.** Probability of losing money in a year = 28.19%\n",
    "\n",
    "**A.iv.** Probability of losing money in a year = 44.97%\n",
    "\n",
    "**A.v.** Expected PnL at the end of one quarter is $10M. The standard deviation for this return is $10M. Expected 2 standard deviation range is hence expected $value \\pm 2SD$ = -$10M to +$30M.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Problem B\n",
    "\n",
    "**A.i.** Probability of losing money in a year = 2.28%\n",
    "\n",
    "**A.ii.** Probability of losing money in a year = 15.87%\n",
    "\n",
    "**A.iii.** Probability of losing money in a year = 28.19%\n",
    "\n",
    "**A.iv.** Probability of losing money in a year = 44.97%\n",
    "\n",
    "**A.v.** Expected PnL at the end of one quarter is $20M. The standard deviation for this return is $20M. Expected 2 standard deviation range is hence expected $value \\pm 2SD$ = -$20M to +$60M.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem C\n",
    "\n",
    "An investor would want to run with leverage to raise returns because “You can’t eat Sharpe ratios”. Raising leverage doesn’t change the win rate, however it raises the size of losses. This can mean that a downturn can wipeout an investor ie. The returns are not ergodic unless the investor can replenish the investment in the fund. 1000% leverage can blow up the entire invested capital in the fund without any hope of recovery. This shows that real-life outcomes are path-dependent due to forced liquidations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem D\n",
    "\n",
    "The answers are depicted in tables below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.i.**\n",
    "\n",
    "In the following table, the columns are the annual returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t2.0\t2.25\t2.5\t2.75\t3.0\t3.25\t3.5\t3.75\t4.0\t4.25\t4.5\t4.75\t5.0\t5.25\t5.5\t5.75\t6.0\t6.25\t6.5\t6.75\t7.0\t7.25\t7.5\t7.75\t8.0\t8.25\t8.5\t8.75\t9.0\t9.25\t9.5\t9.75\t10.0\t10.25\t10.5\t10.75\t11.0\t11.25\t11.5\t11.75\t12.0\n",
      "\tSharpe\t4.0\t3.5556\t3.2\t2.9091\t2.6667\t2.4615\t2.2857\t2.1333\t2.0\t1.8824\t1.7778\t1.6842\t1.6\t1.5238\t1.4545\t1.3913\t1.3333\t1.28\t1.2308\t1.1852\t1.1429\t1.1034\t1.0667\t1.0323\t1.0\t0.9697\t0.9412\t0.9143\t0.8889\t0.8649\t0.8421\t0.8205\t0.8\t0.7805\t0.7619\t0.7442\t0.7273\t0.7111\t0.6957\t0.6809\t0.6667\n",
      "\twWnrate\t0.5995\t0.5886\t0.5799\t0.5727\t0.5667\t0.5616\t0.5572\t0.5535\t0.5501\t0.5472\t0.5446\t0.5422\t0.5401\t0.5382\t0.5365\t0.5349\t0.5335\t0.5321\t0.5309\t0.5298\t0.5287\t0.5277\t0.5268\t0.5259\t0.5251\t0.5244\t0.5236\t0.523\t0.5223\t0.5217\t0.5212\t0.5206\t0.5201\t0.5196\t0.5191\t0.5187\t0.5183\t0.5179\t0.5175\t0.5171\t0.5167\n",
      "\tUp down\t4.7469\t3.7136\t3.1293\t2.7533\t2.4907\t2.297\t2.148\t2.0299\t1.9339\t1.8544\t1.7874\t1.7302\t1.6807\t1.6376\t1.5996\t1.5659\t1.5358\t1.5087\t1.4842\t1.462\t1.4418\t1.4232\t1.4062\t1.3905\t1.3759\t1.3624\t1.3498\t1.3381\t1.3271\t1.3169\t1.3072\t1.2981\t1.2896\t1.2815\t1.2739\t1.2666\t1.2598\t1.2533\t1.2471\t1.2412\t1.2355\n"
     ]
    }
   ],
   "source": [
    "base_ret = 0.08\n",
    "stds = [0.25*num for num in range(8,49)]\n",
    "rets = [norm_ret(base_ret,std/100) for std in stds]\n",
    "sharpes = [ret.get_sharpe() for ret in rets]\n",
    "win_rates = [ret.adjust_time(1/252).get_win_rate() for ret in rets]\n",
    "up_down = [ret.adjust_time(1/252).get_up_down() for ret in rets]\n",
    "data = [sharpes, win_rates, up_down]\n",
    "display_table([\"Sharpe\",\"wWnrate\",\"Up down\"],stds,data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.ii.**\n",
    "In the following, the columns are the annual standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t2.0\t2.25\t2.5\t2.75\t3.0\t3.25\t3.5\t3.75\t4.0\t4.25\t4.5\t4.75\t5.0\t5.25\t5.5\t5.75\t6.0\t6.25\t6.5\t6.75\t7.0\t7.25\t7.5\t7.75\t8.0\t8.25\t8.5\t8.75\t9.0\t9.25\t9.5\t9.75\t10.0\t10.25\t10.5\t10.75\t11.0\t11.25\t11.5\t11.75\t12.0\n",
      "\tSharpe\t0.5\t0.5625\t0.625\t0.6875\t0.75\t0.8125\t0.875\t0.9375\t1.0\t1.0625\t1.125\t1.1875\t1.25\t1.3125\t1.375\t1.4375\t1.5\t1.5625\t1.625\t1.6875\t1.75\t1.8125\t1.875\t1.9375\t2.0\t2.0625\t2.125\t2.1875\t2.25\t2.3125\t2.375\t2.4375\t2.5\t2.5625\t2.625\t2.6875\t2.75\t2.8125\t2.875\t2.9375\t3.0\n",
      "\tWinrate\t0.5126\t0.5141\t0.5157\t0.5173\t0.5188\t0.5204\t0.522\t0.5235\t0.5251\t0.5267\t0.5282\t0.5298\t0.5314\t0.5329\t0.5345\t0.5361\t0.5376\t0.5392\t0.5408\t0.5423\t0.5439\t0.5455\t0.547\t0.5486\t0.5501\t0.5517\t0.5532\t0.5548\t0.5564\t0.5579\t0.5595\t0.561\t0.5626\t0.5641\t0.5657\t0.5672\t0.5688\t0.5703\t0.5719\t0.5734\t0.5749\n",
      "\tUp down\t1.1715\t1.1951\t1.2192\t1.2438\t1.269\t1.2948\t1.3212\t1.3482\t1.3759\t1.4043\t1.4333\t1.4632\t1.4937\t1.5251\t1.5573\t1.5904\t1.6244\t1.6593\t1.6952\t1.7321\t1.7701\t1.8093\t1.8496\t1.8911\t1.9339\t1.9781\t2.0237\t2.0708\t2.1195\t2.1698\t2.2219\t2.2757\t2.3316\t2.3894\t2.4495\t2.5118\t2.5765\t2.6438\t2.7139\t2.7868\t2.8628\n"
     ]
    }
   ],
   "source": [
    "base_std = 0.04\n",
    "base_rets = [0.25*num for num in range(8,49)]\n",
    "rets = [norm_ret(base_ret/100,base_std) for base_ret in base_rets]\n",
    "sharpes = [ret.get_sharpe() for ret in rets]\n",
    "win_rates = [ret.adjust_time(1/252).get_win_rate() for ret in rets]\n",
    "up_down = [ret.adjust_time(1/252).get_up_down() for ret in rets]\n",
    "data = [sharpes, win_rates, up_down]\n",
    "display_table([\"Sharpe\",\"Winrate\",\"Up down\"],base_rets,data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.iii.**\n",
    "\n",
    "It appears that Sharpe ratios, winrates, up down ratios increase together. The normality assumption underlies this effect. It is possible that certain return distributions may have different behaviour due to skewness, ie. we can have a higher win rate with a smaller updown ratio eg. selling options."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem E"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.i.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of drawdown=90 days over time=5 years is 0.9016\n"
     ]
    }
   ],
   "source": [
    "ret_pair = norm_ret(0.08,0.04)\n",
    "time = 5\n",
    "drawdown = 90\n",
    "print(f\"The probability of {drawdown=} days over {time=} years is {prob_drawdown(ret_pair,time,drawdown_days=drawdown)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.ii.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of drawdown=90 days over time=10 years is 0.9906\n"
     ]
    }
   ],
   "source": [
    "time = 10\n",
    "drawdown = 90\n",
    "print(f\"The probability of {drawdown=} days over {time=} years is {prob_drawdown(ret_pair,time,drawdown_days=drawdown)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of drawdown=120 days over time=10 years is 0.9248\n"
     ]
    }
   ],
   "source": [
    "time = 10\n",
    "drawdown = 120\n",
    "print(f\"The probability of {drawdown=} days over {time=} years is {prob_drawdown(ret_pair,time,drawdown_days=drawdown)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition is that longer drawdowns are less likely to be observed. Longer time-periods of observation make drawdowns more likely to be observed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.iii.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-1\t-0.5\t0\t0.5\t1\t1.5\t2\t2.5\t3\n",
      "\t1\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\n",
      "\t3\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\n",
      "\t5\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\n",
      "\t10\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\t1.0\n",
      "\t20\t1.0\t1.0\t1.0\t0.9999\t0.9993\t0.9989\t0.9957\t0.9881\t0.9744\n",
      "\t40\t0.9989\t0.9979\t0.9934\t0.98\t0.9511\t0.9041\t0.8309\t0.7324\t0.6306\n",
      "\t60\t0.9907\t0.9768\t0.9501\t0.8933\t0.8053\t0.707\t0.5667\t0.4341\t0.3003\n",
      "\t90\t0.952\t0.897\t0.8142\t0.7064\t0.5568\t0.4209\t0.2888\t0.1775\t0.1056\n",
      "\t120\t0.8817\t0.7951\t0.6784\t0.5273\t0.3777\t0.242\t0.1418\t0.0802\t0.0369\n"
     ]
    }
   ],
   "source": [
    "drawdown_lengths = [1,3,5,10,20,40,60,90,120]\n",
    "base_std = 0.02\n",
    "sharpes = [-1,-0.5,0,0.5,1,1.5,2,2.5,3]\n",
    "base_rets = [base_std*sharpe for sharpe in sharpes]\n",
    "rets = [norm_ret(rets,base_std) for rets in base_rets]\n",
    "probs = [[prob_drawdown(ret,1,drawdown_days=length) for ret in rets] for length in drawdown_lengths]\n",
    "display_table(drawdown_lengths,sharpes,probs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analysis shows that it is difficult to distinguish different Sharpe ratios by checking for the presence of a drawdown. For example, 20 day drawdown presence is useless in separating any of the Sharpes because all of the strategies are nearly sure to have a drawdown of that length.\n",
    "\n",
    "We must resort to more sophisticated hypothesis testing for distinguishing the two.\n",
    "\n",
    "Further, it shows that short-term performance is hard to distinguish. As a hedge-fund manager, it makes sense to align incentives with longer-term objectives. Another way of mitigating the value\n",
    "of the outside option(leaving the firm in the event of a loss) that a pay-out structure presents to the proprietary\n",
    "trader or hedge fund manager is to hold back compensation as a\n",
    "reserve against possible future drawdowns.\n",
    "\n",
    "The time duration to assess a manager's skill depends on the target Sharpe ratio. For lower Sharpe targets, we need much larger assessment time-periods if the metric is the presence of a drawdown by using a longer window. \n",
    "\n",
    "For higher Sharpe targets, the time duration for assessment can be shorter because differences in drawdown length performances are visible in shorter windows.\n",
    "\n",
    "Under the normality assumption, win-rates and up-down ratios can be a proxy for measuring Sharpe ratio. This works for comparing different strategies if they have the same return characteristics.\n",
    "\n",
    "Consider the following table for daily win rates, up down ratios with Sharpes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-1\t-0.5\t0\t0.5\t1\t1.5\t2\t2.5\t3\n",
      "\t\t0.4749\t0.4874\t0.5\t0.5126\t0.5251\t0.5376\t0.5501\t0.5626\t0.5749\n"
     ]
    }
   ],
   "source": [
    "win_rates = [[ret.adjust_time(1/252).get_win_rate() for ret in rets] for row in range(1)]\n",
    "display_table([\"\"],sharpes,win_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-1\t-0.5\t0\t0.5\t1\t1.5\t2\t2.5\t3\n",
      "\t\t0.7268\t0.8536\t1.0\t1.1715\t1.3759\t1.6244\t1.9339\t2.3316\t2.8628\n"
     ]
    }
   ],
   "source": [
    "up_down = [[ret.adjust_time(1/252).get_up_down() for ret in rets] for row in range(1)]\n",
    "display_table([\"\"],sharpes,up_down)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The win rate parameter can be converted to a hypothesis test with likelihood ratios, assuming negligible autocorrelation in returns. Consider the following code which calculates the posterior likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11008776506017\n"
     ]
    }
   ],
   "source": [
    "#null hypothesis is that the observed distribution is distribution 0\n",
    "def posterior_likelihood(prior_prob1, prior_prob0, win_rate1, win_rate0, num_up_days, num_down_days):\n",
    "    ratio = prior_prob1/prior_prob0*(win_rate1/win_rate0)**num_up_days*((1-win_rate1)/(1-win_rate0))**num_down_days\n",
    "    return ratio\n",
    "eta = 19 # corresponding to a significance level of 0.05\n",
    "#reject null hypothesis if posterior likelihood>eta\n",
    "print(posterior_likelihood(0.5,0.5,0.5749,0.5,24,20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code can be extended to perform Maximum likelihood estimation or Maximum a posteriori estimation on the Sharpe ratio. MLE is easy to perform. We can use the trivial estimator of win_rate then find the Sharpe corresponding to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE estimate is Sharpe = 0.8192\n"
     ]
    }
   ],
   "source": [
    "ret_guess = 0.08\n",
    "std = 0.04\n",
    "\n",
    "num_up_days = 11\n",
    "num_down_days = 10\n",
    "\n",
    "ret_pair = norm_ret(ret_guess,std).adjust_time(1/252)\n",
    "\n",
    "est_win_rate = num_up_days/(num_up_days+num_down_days)\n",
    "win_rate = ret_pair.get_win_rate()\n",
    "\n",
    "tolerance = 1e-8\n",
    "\n",
    "while (win_rate-est_win_rate)/est_win_rate>tolerance:\n",
    "    if win_rate>est_win_rate:\n",
    "        ret_pair.ret*=0.8\n",
    "    else:\n",
    "        ret_pair.ret*=1.1\n",
    "    win_rate = ret_pair.get_win_rate()\n",
    "\n",
    "print(f\"MLE estimate is Sharpe = {ret_pair.adjust_time(252).get_sharpe()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regards to the limits of arbitrage, the above analysis shows that contrarian investing can suffer from misleading statistics for a significant chunk of time ie. when the markets are irrational. It does not make sense to use these methods to quantify performance when returns are not normally distributed, which is the case for some arbitrage opportunities.\n",
    "\n",
    "As for the fundamental law of Active Management, it shows that the breadth of trades placed by a strategy is important in driving a large Sharpe ratio because of the law of large numbers realizing the mean expected returns while driving down volatility.\n",
    "\n",
    "The reports timescale for a manager depends on the target Sharpe ratio, and by extension, the nature of strategies implemented by the manager.\n",
    "For high-frequency trading or other high Sharpe strategies, short-term statistics (on the order of 50-100 days) can be useful in detecting alpha decay(thus our audits can be more responsive).\n",
    "\n",
    "For lower Sharpe strategies, short term statistics are indistinguishable from chance. Thus, we must collect longer-term data.\n",
    "\n",
    "Greater transparency only helps if the statistics generated yield useful information about the strategy. This does not hold true for low-Sharpe strategies such as replicating the index etc. On the other hand, higher frequency reporting can help monitoring performance on a smaller time-scale."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.a.**\n",
    "\n",
    "The horizon of the risk model should decrease with higher Sharpe ratios. Further, the nature of the risk model should change. If we work on a shorter term with higher Sharpes, it is better to use position sizing than a portfolio based approach to risk. This is outlined in the Muller article about strategies with high Sharpe ratios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.b.**\n",
    "\n",
    "The exercise shows that mixing different strategies in portfolio construction may lead to unexpected return and risk characteristics. As mentioned in the Muller article it is better to work towards on strategy with expected Sharpe 2 than combining 5 Sharpe 1 strategies to yield a Sharpe 2.5 strategies, because the underlying strategies may not be actually uncorrelated.\n",
    "\n",
    "Managers need to be fully aware of the interactions of the submodels used in portfolio creation and potential adverse events."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.c.**\n",
    "\n",
    "I want risk managers to control skewness by purchasing option protection against the long down tail and manage kurtosis by tapering positions that become too big. The managers must look for unexpected non-linearities in the returns of \"uncorrelated\" strategies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.d.**\n",
    "\n",
    "Stricter risk guidelines are likely to truncate the tails of the return distribution, thereby reduce the kurtosis of the returns also. This violates the normality assumption and we must adjust for this truncation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.e**\n",
    "\n",
    "Manager innovation helps in discovering new sources of alpha. However, we might see differing risk characteristics in each of the new strategies. This makes it difficult to quantify strategy performance and compare the desirability of different strategies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.f.**\n",
    "\n",
    "This point makes it more desirable to have more frequent data about the performance of the strategy, because of the potential informational value. We must demand as detailed information as possible as investors to understand the risks we are exposed to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.g.**\n",
    "\n",
    "As a manager, I would like to provide as long term information to avoid spooking investors with novel risk characteristics and give myself time to evaluate the strategies at length."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.j.**\n",
    "\n",
    "This exercise has shown that the shiny-new machine learning algorithm must be deployed with care in the absence of a good prior on the risk characteristics of the model. This is even more crucial because of the large role of random chance in the short run, which make it hard to evaluate these strategies and when to shut them down(specific economic conditions etc.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem G\n",
    "\n",
    "Some other metrics of interest are the probability distribution of returns. This can be quantified by the number of large-deviation days that can express the suitability of the assumptions of the form of returns ie. normality, no skew etc. Some examples of these metrics are strategy skewness, kurtosis, Value at Risk(in view of a black swan event), Liquidity requirements.\n",
    "\n",
    "Another useful feature would be to display factor betas for the portfolio. This will show the specific risk premia that we are collecting and the associated considerations.\n",
    "\n",
    "For long-only managers, the Information Ratio—which measures excess returns relative to a benchmark— is more appropriate than Sharpe-ratios as oultined in the Muller article."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem H\n",
    "The win rate is 100%. This does not give a useful bound so let us take that the probability of loss on any day in a year is < 0.5.\n",
    "Thus the win-rate is lower bounded by (0.5)<sup>(1/252)</sup>\n",
    "\n",
    "We search for the answer with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sharpe is atleast 2.77648194462532\n"
     ]
    }
   ],
   "source": [
    "tolerance = 1e-6\n",
    "seed_std = 0.02\n",
    "seed_ret = 0.08\n",
    "p_lossday_in_year = 0.50\n",
    "target_win_rate = (1-p_lossday_in_year)**(1/252)\n",
    "helper = norm_ret(seed_ret,seed_std)\n",
    "win_rate = helper.get_win_rate()\n",
    "while abs((win_rate-target_win_rate)/target_win_rate)>tolerance:\n",
    "    if win_rate<target_win_rate:\n",
    "        helper.std*=0.5\n",
    "    else:\n",
    "        helper.std*=1.2\n",
    "    win_rate = helper.get_win_rate()\n",
    "print(f\"Target Sharpe is atleast {helper.get_sharpe()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
